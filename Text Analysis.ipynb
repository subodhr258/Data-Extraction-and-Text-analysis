{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274d6257",
   "metadata": {},
   "source": [
    "## Testing Text Analysis for one article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da80863",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"articles/1.txt\",\"r\",encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd18f729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When people hear AI they often think about sentient robots and magic boxes. AI today is much more mundane and simple—but that doesn’t mean it’s not powerful. Another misconception is that high-profile research projects can be applied directly to any business situation. AI done right can create an extreme return on investments (ROIs)—for instance through automation or precise prediction. But it does take thought, time, and proper implementation. We have seen that success and value generated by AI projects are increased when there is a grounded understanding and expectation of what the technology can deliver from the C-suite down.\\n“Artificial Intelligence (AI) is a science and a set of computational technologies that are inspired by—but typically operate quite differently from—the ways people use their nervous systems and bodies to sense, learn, reason and take action.”3 Lately there has been a big rise in the day-to-day use of machines powered by AI. These machines are wired using cross-disciplinary approaches based on mathematics, computer science, statistics, psychology, and more.4 Virtual assistants are becoming more common, most of the web shops predict your purchases, many companies make use of chatbots in their customer service and many companies use algorithms to detect fraud.\\nAI and Deep Learning technology employed in office entry systems will bring proper time tracking of each employee. As this system tries to learn each person with an image processing technology whose data is feed forwarded to a deep learning model where Deep learning isn’t an algorithm per se, but rather a family of algorithms that implements deep networks (many layers). These networks are so deep that new methods of computation, such as graphics processing units (GPUs), are required to train them, in addition to clusters of compute nodes. So using deep learning we can take detect the employee using face and person recognition scan and through which login, logout timing is recorded. Using an AI system we can even identify each employee’s entry time, their working hours, non-working hours by tracking the movement of an employee in the office so that system can predict and report HR for the salary for each employee based on their working hours. Our system can take feed from CCTV to track movements of employees and this system is capable of recognizing a person even he/she is being masked as in this pandemic situation by taking their iris scan. With this system installed inside the office, the following are some of the benefits:\\n1)Compliance/litigation needs\\nFor several countries, regulations insist that the employer must keep documents available that can demonstrate the working hours performed by each employee. In the event of control from the labor inspectorate or a dispute with an employee, the employer must be able to explain and justify the working hours for the company. This can be made easy as our system is tracking employee movements\\n2)Information security needs\\nThis is about monitoring user connection times to detect suspicious access times. In the event where compromised credentials are used to log on at 3 a.m. on a Saturday, a notification on this access could alert the IT team that an attack is possibly underway.\\n3)Employee login logout software\\nTo manage and react to employees’ attendance, overtime thresholds, productivity, and suspicious access times, our system records and stores detailed and interactive reporting on users’ connection times. These records allow you to better manage users’ connection times and provide accurate, detailed data required by management.\\n4)If you want to avoid paying overtime, make sure that your employees respect certain working time quotas or even avoid suspicious access. Our system will alert the HR officer about each employee’s office in and out time so that they can accordingly take action.\\n5)Last but not least it reduces human resource needs to keep track of the records and sending the report to HR and HR officials has to check through the report so this system will reduce times and human resource needs\\nWith the use of AI and Deep Learning technologies, we can automate some routines stuff with more functionality which humans need more resources to keep track thereby reducing time spent on manual data entry works rather companies can think of making their position high in the competitive world.\\nBlackcoffer Insights 33: Suriya E, Vellore Institute of Technology\\nShare:'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5ac37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd60327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12760457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27331236",
   "metadata": {},
   "source": [
    "### Removing Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fd3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open(\"StopWords_Generic.txt\",\"r\").read()\n",
    "#Downloaded stop words list of 121 stopwords from the given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90653c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e32faa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76529e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text= [word for word in words if word.upper() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80ee9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(803, 532)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8fb76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people',\n",
       " 'hear',\n",
       " 'AI',\n",
       " 'often',\n",
       " 'think',\n",
       " 'sentient',\n",
       " 'robots',\n",
       " 'magic',\n",
       " 'boxes',\n",
       " '.',\n",
       " 'AI',\n",
       " 'today',\n",
       " 'much',\n",
       " 'mundane',\n",
       " 'simple—but',\n",
       " 'doesn',\n",
       " '’',\n",
       " 't',\n",
       " 'mean',\n",
       " '’',\n",
       " 's',\n",
       " 'powerful',\n",
       " '.',\n",
       " 'Another',\n",
       " 'misconception',\n",
       " 'high-profile',\n",
       " 'research',\n",
       " 'projects',\n",
       " 'applied',\n",
       " 'directly',\n",
       " 'business',\n",
       " 'situation',\n",
       " '.',\n",
       " 'AI',\n",
       " 'done',\n",
       " 'right',\n",
       " 'create',\n",
       " 'extreme',\n",
       " 'return',\n",
       " 'investments',\n",
       " '(',\n",
       " 'ROIs',\n",
       " ')',\n",
       " '—for',\n",
       " 'instance',\n",
       " 'automation',\n",
       " 'precise',\n",
       " 'prediction',\n",
       " '.',\n",
       " 'take',\n",
       " 'thought',\n",
       " ',',\n",
       " 'time',\n",
       " ',',\n",
       " 'proper',\n",
       " 'implementation',\n",
       " '.',\n",
       " 'seen',\n",
       " 'success',\n",
       " 'value',\n",
       " 'generated',\n",
       " 'AI',\n",
       " 'projects',\n",
       " 'increased',\n",
       " 'a',\n",
       " 'grounded',\n",
       " 'understanding',\n",
       " 'expectation',\n",
       " 'technology',\n",
       " 'deliver',\n",
       " 'C-suite',\n",
       " '.',\n",
       " '“',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'a',\n",
       " 'science',\n",
       " 'a',\n",
       " 'set',\n",
       " 'computational',\n",
       " 'technologies',\n",
       " 'inspired',\n",
       " 'by—but',\n",
       " 'typically',\n",
       " 'operate',\n",
       " 'quite',\n",
       " 'differently',\n",
       " 'from—the',\n",
       " 'ways',\n",
       " 'people',\n",
       " 'use',\n",
       " 'nervous',\n",
       " 'systems',\n",
       " 'bodies',\n",
       " 'sense',\n",
       " ',',\n",
       " 'learn',\n",
       " ',',\n",
       " 'reason',\n",
       " 'take',\n",
       " 'action.',\n",
       " '”',\n",
       " '3',\n",
       " 'Lately',\n",
       " 'a',\n",
       " 'big',\n",
       " 'rise',\n",
       " 'day-to-day',\n",
       " 'use',\n",
       " 'machines',\n",
       " 'powered',\n",
       " 'AI',\n",
       " '.',\n",
       " 'machines',\n",
       " 'wired',\n",
       " 'using',\n",
       " 'cross-disciplinary',\n",
       " 'approaches',\n",
       " 'based',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'psychology',\n",
       " ',',\n",
       " 'more.4',\n",
       " 'Virtual',\n",
       " 'assistants',\n",
       " 'becoming',\n",
       " 'common',\n",
       " ',',\n",
       " 'web',\n",
       " 'shops',\n",
       " 'predict',\n",
       " 'purchases',\n",
       " ',',\n",
       " 'many',\n",
       " 'companies',\n",
       " 'make',\n",
       " 'use',\n",
       " 'chatbots',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'many',\n",
       " 'companies',\n",
       " 'use',\n",
       " 'algorithms',\n",
       " 'detect',\n",
       " 'fraud',\n",
       " '.',\n",
       " 'AI',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'technology',\n",
       " 'employed',\n",
       " 'office',\n",
       " 'entry',\n",
       " 'systems',\n",
       " 'will',\n",
       " 'bring',\n",
       " 'proper',\n",
       " 'time',\n",
       " 'tracking',\n",
       " 'employee',\n",
       " '.',\n",
       " 'system',\n",
       " 'tries',\n",
       " 'learn',\n",
       " 'person',\n",
       " 'image',\n",
       " 'processing',\n",
       " 'technology',\n",
       " 'whose',\n",
       " 'data',\n",
       " 'feed',\n",
       " 'forwarded',\n",
       " 'a',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'model',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'isn',\n",
       " '’',\n",
       " 't',\n",
       " 'algorithm',\n",
       " 'per',\n",
       " 'se',\n",
       " ',',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'family',\n",
       " 'algorithms',\n",
       " 'implements',\n",
       " 'deep',\n",
       " 'networks',\n",
       " '(',\n",
       " 'many',\n",
       " 'layers',\n",
       " ')',\n",
       " '.',\n",
       " 'networks',\n",
       " 'deep',\n",
       " 'new',\n",
       " 'methods',\n",
       " 'computation',\n",
       " ',',\n",
       " 'graphics',\n",
       " 'processing',\n",
       " 'units',\n",
       " '(',\n",
       " 'GPUs',\n",
       " ')',\n",
       " ',',\n",
       " 'required',\n",
       " 'train',\n",
       " ',',\n",
       " 'addition',\n",
       " 'clusters',\n",
       " 'compute',\n",
       " 'nodes',\n",
       " '.',\n",
       " 'using',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'take',\n",
       " 'detect',\n",
       " 'employee',\n",
       " 'using',\n",
       " 'face',\n",
       " 'person',\n",
       " 'recognition',\n",
       " 'scan',\n",
       " 'login',\n",
       " ',',\n",
       " 'logout',\n",
       " 'timing',\n",
       " 'recorded',\n",
       " '.',\n",
       " 'Using',\n",
       " 'AI',\n",
       " 'system',\n",
       " 'even',\n",
       " 'identify',\n",
       " 'employee',\n",
       " '’',\n",
       " 's',\n",
       " 'entry',\n",
       " 'time',\n",
       " ',',\n",
       " 'working',\n",
       " 'hours',\n",
       " ',',\n",
       " 'non-working',\n",
       " 'hours',\n",
       " 'tracking',\n",
       " 'movement',\n",
       " 'employee',\n",
       " 'office',\n",
       " 'system',\n",
       " 'predict',\n",
       " 'report',\n",
       " 'HR',\n",
       " 'salary',\n",
       " 'employee',\n",
       " 'based',\n",
       " 'working',\n",
       " 'hours',\n",
       " '.',\n",
       " 'system',\n",
       " 'take',\n",
       " 'feed',\n",
       " 'CCTV',\n",
       " 'track',\n",
       " 'movements',\n",
       " 'employees',\n",
       " 'system',\n",
       " 'capable',\n",
       " 'recognizing',\n",
       " 'a',\n",
       " 'person',\n",
       " 'even',\n",
       " 'he/she',\n",
       " 'masked',\n",
       " 'pandemic',\n",
       " 'situation',\n",
       " 'taking',\n",
       " 'iris',\n",
       " 'scan',\n",
       " '.',\n",
       " 'system',\n",
       " 'installed',\n",
       " 'inside',\n",
       " 'office',\n",
       " ',',\n",
       " 'following',\n",
       " 'benefits',\n",
       " ':',\n",
       " '1',\n",
       " ')',\n",
       " 'Compliance/litigation',\n",
       " 'needs',\n",
       " 'several',\n",
       " 'countries',\n",
       " ',',\n",
       " 'regulations',\n",
       " 'insist',\n",
       " 'employer',\n",
       " 'must',\n",
       " 'keep',\n",
       " 'documents',\n",
       " 'available',\n",
       " 'demonstrate',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'performed',\n",
       " 'employee',\n",
       " '.',\n",
       " 'event',\n",
       " 'control',\n",
       " 'labor',\n",
       " 'inspectorate',\n",
       " 'a',\n",
       " 'dispute',\n",
       " 'employee',\n",
       " ',',\n",
       " 'employer',\n",
       " 'must',\n",
       " 'able',\n",
       " 'explain',\n",
       " 'justify',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'company',\n",
       " '.',\n",
       " 'made',\n",
       " 'easy',\n",
       " 'system',\n",
       " 'tracking',\n",
       " 'employee',\n",
       " 'movements',\n",
       " '2',\n",
       " ')',\n",
       " 'Information',\n",
       " 'security',\n",
       " 'needs',\n",
       " 'monitoring',\n",
       " 'user',\n",
       " 'connection',\n",
       " 'times',\n",
       " 'detect',\n",
       " 'suspicious',\n",
       " 'access',\n",
       " 'times',\n",
       " '.',\n",
       " 'event',\n",
       " 'compromised',\n",
       " 'credentials',\n",
       " 'used',\n",
       " 'log',\n",
       " '3',\n",
       " 'a.m.',\n",
       " 'a',\n",
       " 'Saturday',\n",
       " ',',\n",
       " 'a',\n",
       " 'notification',\n",
       " 'access',\n",
       " 'could',\n",
       " 'alert',\n",
       " 'team',\n",
       " 'attack',\n",
       " 'possibly',\n",
       " 'underway',\n",
       " '.',\n",
       " '3',\n",
       " ')',\n",
       " 'Employee',\n",
       " 'login',\n",
       " 'logout',\n",
       " 'software',\n",
       " 'manage',\n",
       " 'react',\n",
       " 'employees',\n",
       " '’',\n",
       " 'attendance',\n",
       " ',',\n",
       " 'overtime',\n",
       " 'thresholds',\n",
       " ',',\n",
       " 'productivity',\n",
       " ',',\n",
       " 'suspicious',\n",
       " 'access',\n",
       " 'times',\n",
       " ',',\n",
       " 'system',\n",
       " 'records',\n",
       " 'stores',\n",
       " 'detailed',\n",
       " 'interactive',\n",
       " 'reporting',\n",
       " 'users',\n",
       " '’',\n",
       " 'connection',\n",
       " 'times',\n",
       " '.',\n",
       " 'records',\n",
       " 'allow',\n",
       " 'better',\n",
       " 'manage',\n",
       " 'users',\n",
       " '’',\n",
       " 'connection',\n",
       " 'times',\n",
       " 'provide',\n",
       " 'accurate',\n",
       " ',',\n",
       " 'detailed',\n",
       " 'data',\n",
       " 'required',\n",
       " 'management',\n",
       " '.',\n",
       " '4',\n",
       " ')',\n",
       " 'want',\n",
       " 'avoid',\n",
       " 'paying',\n",
       " 'overtime',\n",
       " ',',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'employees',\n",
       " 'respect',\n",
       " 'certain',\n",
       " 'working',\n",
       " 'time',\n",
       " 'quotas',\n",
       " 'even',\n",
       " 'avoid',\n",
       " 'suspicious',\n",
       " 'access',\n",
       " '.',\n",
       " 'system',\n",
       " 'will',\n",
       " 'alert',\n",
       " 'HR',\n",
       " 'officer',\n",
       " 'employee',\n",
       " '’',\n",
       " 's',\n",
       " 'office',\n",
       " 'time',\n",
       " 'accordingly',\n",
       " 'take',\n",
       " 'action',\n",
       " '.',\n",
       " '5',\n",
       " ')',\n",
       " 'Last',\n",
       " 'least',\n",
       " 'reduces',\n",
       " 'human',\n",
       " 'resource',\n",
       " 'needs',\n",
       " 'keep',\n",
       " 'track',\n",
       " 'records',\n",
       " 'sending',\n",
       " 'report',\n",
       " 'HR',\n",
       " 'HR',\n",
       " 'officials',\n",
       " 'check',\n",
       " 'report',\n",
       " 'system',\n",
       " 'will',\n",
       " 'reduce',\n",
       " 'times',\n",
       " 'human',\n",
       " 'resource',\n",
       " 'needs',\n",
       " 'use',\n",
       " 'AI',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'technologies',\n",
       " ',',\n",
       " 'automate',\n",
       " 'routines',\n",
       " 'stuff',\n",
       " 'functionality',\n",
       " 'humans',\n",
       " 'need',\n",
       " 'resources',\n",
       " 'keep',\n",
       " 'track',\n",
       " 'thereby',\n",
       " 'reducing',\n",
       " 'time',\n",
       " 'spent',\n",
       " 'manual',\n",
       " 'data',\n",
       " 'entry',\n",
       " 'works',\n",
       " 'rather',\n",
       " 'companies',\n",
       " 'think',\n",
       " 'making',\n",
       " 'position',\n",
       " 'high',\n",
       " 'competitive',\n",
       " 'world',\n",
       " '.',\n",
       " 'Blackcoffer',\n",
       " 'Insights',\n",
       " '33',\n",
       " ':',\n",
       " 'Suriya',\n",
       " 'E',\n",
       " ',',\n",
       " 'Vellore',\n",
       " 'Institute',\n",
       " 'Technology',\n",
       " 'Share',\n",
       " ':']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1a257",
   "metadata": {},
   "source": [
    "### We can also remove all punctuations and numbers to further clean the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a13ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = [word for word in cleaned_text if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de6228f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c50df87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people',\n",
       " 'hear',\n",
       " 'AI',\n",
       " 'often',\n",
       " 'think',\n",
       " 'sentient',\n",
       " 'robots',\n",
       " 'magic',\n",
       " 'boxes',\n",
       " 'AI',\n",
       " 'today',\n",
       " 'much',\n",
       " 'mundane',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'mean',\n",
       " 's',\n",
       " 'powerful',\n",
       " 'Another',\n",
       " 'misconception',\n",
       " 'research',\n",
       " 'projects',\n",
       " 'applied',\n",
       " 'directly',\n",
       " 'business',\n",
       " 'situation',\n",
       " 'AI',\n",
       " 'done',\n",
       " 'right',\n",
       " 'create',\n",
       " 'extreme',\n",
       " 'return',\n",
       " 'investments',\n",
       " 'ROIs',\n",
       " 'instance',\n",
       " 'automation',\n",
       " 'precise',\n",
       " 'prediction',\n",
       " 'take',\n",
       " 'thought',\n",
       " 'time',\n",
       " 'proper',\n",
       " 'implementation',\n",
       " 'seen',\n",
       " 'success',\n",
       " 'value',\n",
       " 'generated',\n",
       " 'AI',\n",
       " 'projects',\n",
       " 'increased',\n",
       " 'a',\n",
       " 'grounded',\n",
       " 'understanding',\n",
       " 'expectation',\n",
       " 'technology',\n",
       " 'deliver',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'AI',\n",
       " 'a',\n",
       " 'science',\n",
       " 'a',\n",
       " 'set',\n",
       " 'computational',\n",
       " 'technologies',\n",
       " 'inspired',\n",
       " 'typically',\n",
       " 'operate',\n",
       " 'quite',\n",
       " 'differently',\n",
       " 'ways',\n",
       " 'people',\n",
       " 'use',\n",
       " 'nervous',\n",
       " 'systems',\n",
       " 'bodies',\n",
       " 'sense',\n",
       " 'learn',\n",
       " 'reason',\n",
       " 'take',\n",
       " 'Lately',\n",
       " 'a',\n",
       " 'big',\n",
       " 'rise',\n",
       " 'use',\n",
       " 'machines',\n",
       " 'powered',\n",
       " 'AI',\n",
       " 'machines',\n",
       " 'wired',\n",
       " 'using',\n",
       " 'approaches',\n",
       " 'based',\n",
       " 'mathematics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'statistics',\n",
       " 'psychology',\n",
       " 'Virtual',\n",
       " 'assistants',\n",
       " 'becoming',\n",
       " 'common',\n",
       " 'web',\n",
       " 'shops',\n",
       " 'predict',\n",
       " 'purchases',\n",
       " 'many',\n",
       " 'companies',\n",
       " 'make',\n",
       " 'use',\n",
       " 'chatbots',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'many',\n",
       " 'companies',\n",
       " 'use',\n",
       " 'algorithms',\n",
       " 'detect',\n",
       " 'fraud',\n",
       " 'AI',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'technology',\n",
       " 'employed',\n",
       " 'office',\n",
       " 'entry',\n",
       " 'systems',\n",
       " 'will',\n",
       " 'bring',\n",
       " 'proper',\n",
       " 'time',\n",
       " 'tracking',\n",
       " 'employee',\n",
       " 'system',\n",
       " 'tries',\n",
       " 'learn',\n",
       " 'person',\n",
       " 'image',\n",
       " 'processing',\n",
       " 'technology',\n",
       " 'whose',\n",
       " 'data',\n",
       " 'feed',\n",
       " 'forwarded',\n",
       " 'a',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'model',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'isn',\n",
       " 't',\n",
       " 'algorithm',\n",
       " 'per',\n",
       " 'se',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'family',\n",
       " 'algorithms',\n",
       " 'implements',\n",
       " 'deep',\n",
       " 'networks',\n",
       " 'many',\n",
       " 'layers',\n",
       " 'networks',\n",
       " 'deep',\n",
       " 'new',\n",
       " 'methods',\n",
       " 'computation',\n",
       " 'graphics',\n",
       " 'processing',\n",
       " 'units',\n",
       " 'GPUs',\n",
       " 'required',\n",
       " 'train',\n",
       " 'addition',\n",
       " 'clusters',\n",
       " 'compute',\n",
       " 'nodes',\n",
       " 'using',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'take',\n",
       " 'detect',\n",
       " 'employee',\n",
       " 'using',\n",
       " 'face',\n",
       " 'person',\n",
       " 'recognition',\n",
       " 'scan',\n",
       " 'login',\n",
       " 'logout',\n",
       " 'timing',\n",
       " 'recorded',\n",
       " 'Using',\n",
       " 'AI',\n",
       " 'system',\n",
       " 'even',\n",
       " 'identify',\n",
       " 'employee',\n",
       " 's',\n",
       " 'entry',\n",
       " 'time',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'hours',\n",
       " 'tracking',\n",
       " 'movement',\n",
       " 'employee',\n",
       " 'office',\n",
       " 'system',\n",
       " 'predict',\n",
       " 'report',\n",
       " 'HR',\n",
       " 'salary',\n",
       " 'employee',\n",
       " 'based',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'system',\n",
       " 'take',\n",
       " 'feed',\n",
       " 'CCTV',\n",
       " 'track',\n",
       " 'movements',\n",
       " 'employees',\n",
       " 'system',\n",
       " 'capable',\n",
       " 'recognizing',\n",
       " 'a',\n",
       " 'person',\n",
       " 'even',\n",
       " 'masked',\n",
       " 'pandemic',\n",
       " 'situation',\n",
       " 'taking',\n",
       " 'iris',\n",
       " 'scan',\n",
       " 'system',\n",
       " 'installed',\n",
       " 'inside',\n",
       " 'office',\n",
       " 'following',\n",
       " 'benefits',\n",
       " 'needs',\n",
       " 'several',\n",
       " 'countries',\n",
       " 'regulations',\n",
       " 'insist',\n",
       " 'employer',\n",
       " 'must',\n",
       " 'keep',\n",
       " 'documents',\n",
       " 'available',\n",
       " 'demonstrate',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'performed',\n",
       " 'employee',\n",
       " 'event',\n",
       " 'control',\n",
       " 'labor',\n",
       " 'inspectorate',\n",
       " 'a',\n",
       " 'dispute',\n",
       " 'employee',\n",
       " 'employer',\n",
       " 'must',\n",
       " 'able',\n",
       " 'explain',\n",
       " 'justify',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'company',\n",
       " 'made',\n",
       " 'easy',\n",
       " 'system',\n",
       " 'tracking',\n",
       " 'employee',\n",
       " 'movements',\n",
       " 'Information',\n",
       " 'security',\n",
       " 'needs',\n",
       " 'monitoring',\n",
       " 'user',\n",
       " 'connection',\n",
       " 'times',\n",
       " 'detect',\n",
       " 'suspicious',\n",
       " 'access',\n",
       " 'times',\n",
       " 'event',\n",
       " 'compromised',\n",
       " 'credentials',\n",
       " 'used',\n",
       " 'log',\n",
       " 'a',\n",
       " 'Saturday',\n",
       " 'a',\n",
       " 'notification',\n",
       " 'access',\n",
       " 'could',\n",
       " 'alert',\n",
       " 'team',\n",
       " 'attack',\n",
       " 'possibly',\n",
       " 'underway',\n",
       " 'Employee',\n",
       " 'login',\n",
       " 'logout',\n",
       " 'software',\n",
       " 'manage',\n",
       " 'react',\n",
       " 'employees',\n",
       " 'attendance',\n",
       " 'overtime',\n",
       " 'thresholds',\n",
       " 'productivity',\n",
       " 'suspicious',\n",
       " 'access',\n",
       " 'times',\n",
       " 'system',\n",
       " 'records',\n",
       " 'stores',\n",
       " 'detailed',\n",
       " 'interactive',\n",
       " 'reporting',\n",
       " 'users',\n",
       " 'connection',\n",
       " 'times',\n",
       " 'records',\n",
       " 'allow',\n",
       " 'better',\n",
       " 'manage',\n",
       " 'users',\n",
       " 'connection',\n",
       " 'times',\n",
       " 'provide',\n",
       " 'accurate',\n",
       " 'detailed',\n",
       " 'data',\n",
       " 'required',\n",
       " 'management',\n",
       " 'want',\n",
       " 'avoid',\n",
       " 'paying',\n",
       " 'overtime',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'employees',\n",
       " 'respect',\n",
       " 'certain',\n",
       " 'working',\n",
       " 'time',\n",
       " 'quotas',\n",
       " 'even',\n",
       " 'avoid',\n",
       " 'suspicious',\n",
       " 'access',\n",
       " 'system',\n",
       " 'will',\n",
       " 'alert',\n",
       " 'HR',\n",
       " 'officer',\n",
       " 'employee',\n",
       " 's',\n",
       " 'office',\n",
       " 'time',\n",
       " 'accordingly',\n",
       " 'take',\n",
       " 'action',\n",
       " 'Last',\n",
       " 'least',\n",
       " 'reduces',\n",
       " 'human',\n",
       " 'resource',\n",
       " 'needs',\n",
       " 'keep',\n",
       " 'track',\n",
       " 'records',\n",
       " 'sending',\n",
       " 'report',\n",
       " 'HR',\n",
       " 'HR',\n",
       " 'officials',\n",
       " 'check',\n",
       " 'report',\n",
       " 'system',\n",
       " 'will',\n",
       " 'reduce',\n",
       " 'times',\n",
       " 'human',\n",
       " 'resource',\n",
       " 'needs',\n",
       " 'use',\n",
       " 'AI',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'technologies',\n",
       " 'automate',\n",
       " 'routines',\n",
       " 'stuff',\n",
       " 'functionality',\n",
       " 'humans',\n",
       " 'need',\n",
       " 'resources',\n",
       " 'keep',\n",
       " 'track',\n",
       " 'thereby',\n",
       " 'reducing',\n",
       " 'time',\n",
       " 'spent',\n",
       " 'manual',\n",
       " 'data',\n",
       " 'entry',\n",
       " 'works',\n",
       " 'rather',\n",
       " 'companies',\n",
       " 'think',\n",
       " 'making',\n",
       " 'position',\n",
       " 'high',\n",
       " 'competitive',\n",
       " 'world',\n",
       " 'Blackcoffer',\n",
       " 'Insights',\n",
       " 'Suriya',\n",
       " 'E',\n",
       " 'Vellore',\n",
       " 'Institute',\n",
       " 'Technology',\n",
       " 'Share']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9252663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have successfully cleaned the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700bf0a7",
   "metadata": {},
   "source": [
    "### Creating dictionary of Positive and Negative words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da025892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79602001",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDict = pd.read_csv('MasterDictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e27543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86531, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f1ca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>1.550080e-08</td>\n",
       "      <td>1.422600e-08</td>\n",
       "      <td>3.815486e-06</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.313627e-10</td>\n",
       "      <td>8.653817e-12</td>\n",
       "      <td>9.241714e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.940882e-10</td>\n",
       "      <td>1.169679e-10</td>\n",
       "      <td>5.290465e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.269840e-09</td>\n",
       "      <td>6.654735e-10</td>\n",
       "      <td>1.595100e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>8570</td>\n",
       "      <td>3.752595e-07</td>\n",
       "      <td>3.809464e-07</td>\n",
       "      <td>3.529356e-05</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Seq_num  Word Count  Word Proportion  Average Proportion  \\\n",
       "0   AARDVARK        1         354     1.550080e-08        1.422600e-08   \n",
       "1  AARDVARKS        2           3     1.313627e-10        8.653817e-12   \n",
       "2      ABACI        3           9     3.940882e-10        1.169679e-10   \n",
       "3      ABACK        4          29     1.269840e-09        6.654735e-10   \n",
       "4     ABACUS        5        8570     3.752595e-07        3.809464e-07   \n",
       "\n",
       "        Std Dev  Doc Count  Negative  Positive  Uncertainty  Litigious  \\\n",
       "0  3.815486e-06         99         0         0            0          0   \n",
       "1  9.241714e-09          1         0         0            0          0   \n",
       "2  5.290465e-08          7         0         0            0          0   \n",
       "3  1.595100e-07         28         0         0            0          0   \n",
       "4  3.529356e-05       1108         0         0            0          0   \n",
       "\n",
       "   Strong_Modal  Weak_Modal  Constraining  Syllables     Source  \n",
       "0             0           0             0          2  12of12inf  \n",
       "1             0           0             0          2  12of12inf  \n",
       "2             0           0             0          3  12of12inf  \n",
       "3             0           0             0          2  12of12inf  \n",
       "4             0           0             0          3  12of12inf  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74a7e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0       84176\n",
       " 2009     2305\n",
       " 2014       26\n",
       " 2011       13\n",
       "-2020       10\n",
       " 2012        1\n",
       "Name: Negative, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDict['Negative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "255d3a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0       86177\n",
       " 2009      345\n",
       "-2020        7\n",
       " 2012        1\n",
       " 2011        1\n",
       "Name: Positive, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDict['Positive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9b8adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we can conclude from this that around 2300 words are negative and around 350 words are positive.\n",
    "#Rest of the words are assumed to be neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f180cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can extract these words in 2 lists of Negative and Positive words:\n",
    "positive = masterDict[masterDict['Positive']!=0]['Word'].tolist()\n",
    "negative = masterDict[masterDict['Negative']!=0]['Word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d17f417b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 2355)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive), len(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a20d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using these two lists to seggregate cleaned_text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f73078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = [word for word in cleaned_text if word.upper() in positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c079e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = [word for word in cleaned_text if word.upper() in negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9b3110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_words),len(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa8a6794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['success', 'able', 'easy', 'better']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cf82091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud', 'dispute', 'suspicious', 'suspicious', 'suspicious']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca49cb6",
   "metadata": {},
   "source": [
    "### Extracting Derived variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc630d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since positive score is the number of positive words, and same for negative score:\n",
    "positive_score = len(positive_words)\n",
    "negative_score = len(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d314f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_score = (positive_score-negative_score)/((positive_score+negative_score)+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fab5d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11111109876543349"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_score #ranging from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c41e192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_score = (positive_score+negative_score)/(len(cleaned_text)+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99e28ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020833333285108026"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65cc1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence we have calculated the positive score, negative score, polarity score and subjectivity score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6fafd",
   "metadata": {},
   "source": [
    "### Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da0fc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f3d49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbd498b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d1deb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When people hear AI they often think about sentient robots and magic boxes.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e989df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in words if word.isalpha()] #removing punctuation and numbers from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81530224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d778e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentence_length = len(words)/len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d84f0ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.291666666666668"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "948164bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To count the number of syllables in a word, we can count the number of vowels, but it will be inaccurate,\n",
    "#as there can be words with 'ee', 'ou', 'y' etc. where the calculated syllables will be more than actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d990b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can create a function for counting syllables: (this is almost always accurate at counting syllables.)\n",
    "def count_syllables(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    if word[0] in vowels:#for the first vowel\n",
    "        count += 1\n",
    "    for i in range(1, len(word)):\n",
    "        if word[i] in vowels and word[i-1] not in vowels:#eliminates grouped vowels\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):#usually this isn't considered as a syllable\n",
    "        count -= 1\n",
    "    if count == 0:#The word should have at least one syllable.\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "129938a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "complex_count = 0\n",
    "for word in words:\n",
    "    if count_syllables(word)>2:\n",
    "        complex_count+=1\n",
    "print(complex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34e9fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so there are 123 complex words in the first article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df3d5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_complex_words = complex_count/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f422a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16642958748221906"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "749e0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fog_index = 0.4 * (avg_sentence_length + perc_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "640f8c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.783238501659556"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fog_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccff0c",
   "metadata": {},
   "source": [
    "### Personal Pronouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9006b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate the number of personal pronouns, we can use a regexParser and nltk.pos_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4262c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRP personal pronoun –  I, he, she, etc. \n",
    "# PRP$ possessive pronoun – my, his, hers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffb91230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar = r\"P: {<PRP>}\"\n",
    "# parser =nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3fb41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This matches other personal pronouns too, that we might not want.\n",
    "#So we can just use regex matching manually using 're'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f76c66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5646a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prp = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "#re.I ignores the case, \"us\" is an exception, the case for that must match too.\n",
    "#An alternative is using word boundaries by \"\\b\" and \"|\" in regex parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2e7b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_pronouns = len(prp.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63b9e7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08b8b5",
   "metadata": {},
   "source": [
    "### Average Word Length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82a3558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_chars = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df3581b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    sum_chars+=len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4007d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_length = sum_chars/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7840b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0369843527738265"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_word_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb38ad",
   "metadata": {},
   "source": [
    "### Word Count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cac80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce1600",
   "metadata": {},
   "source": [
    "### Syllables per word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cab8787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_syllables = 0\n",
    "for word in cleaned_text:\n",
    "    tot_syllables += count_syllables(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc51ede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9040632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables_per_word = tot_syllables/word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93ceb6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.025462962962963"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables_per_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ab30a",
   "metadata": {},
   "source": [
    "## Results of Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "043b960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Positive Score :          4\n",
      "                          Negative Score :          5\n",
      "                          Polarity Score :      -0.11\n",
      "                      Subjectivity Score :       0.02\n",
      "                 Average Sentence Length :      29.29\n",
      "             Percentage of Complex Words :       0.17\n",
      "                               Fog Index :      11.78\n",
      "          Avg. no. of words per sentence :      29.29\n",
      "                      Complex Word Count :        117\n",
      "                              Word Count :        432\n",
      "                       Syllable per word :       2.03\n",
      "                       Personal Pronouns :          4\n",
      "                     Average word length :       5.04\n"
     ]
    }
   ],
   "source": [
    "print(\"{: >40} : {: >10}\".format(\"Positive Score\",round(positive_score,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Negative Score\",round(negative_score,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Polarity Score\",round(polarity_score,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Subjectivity Score\",round(subjectivity_score,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Average Sentence Length\",round(avg_sentence_length,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Percentage of Complex Words\",round(perc_complex_words,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Fog Index\",round(fog_index,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Avg. no. of words per sentence\",round(avg_sentence_length,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Complex Word Count\",round(complex_count,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Word Count\",round(word_count,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Syllable per word\",round(syllables_per_word,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Personal Pronouns\",round(personal_pronouns,2)))\n",
    "print(\"{: >40} : {: >10}\".format(\"Average word length\",round(avg_word_length,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa853f",
   "metadata": {},
   "source": [
    "# Final Text Analysis for all articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9254bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we know that there are 170 articles, so we can iterate on each URL_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "125d45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Output Data Structure.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2189430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0     1.0  https://insights.blackcoffer.com/how-is-login-...             NaN   \n",
       "1     2.0  https://insights.blackcoffer.com/how-does-ai-h...             NaN   \n",
       "2     3.0  https://insights.blackcoffer.com/ai-and-its-im...             NaN   \n",
       "3     4.0  https://insights.blackcoffer.com/how-do-deep-l...             NaN   \n",
       "4     5.0  https://insights.blackcoffer.com/how-artificia...             NaN   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             NaN             NaN                 NaN                  NaN   \n",
       "1             NaN             NaN                 NaN                  NaN   \n",
       "2             NaN             NaN                 NaN                  NaN   \n",
       "3             NaN             NaN                 NaN                  NaN   \n",
       "4             NaN             NaN                 NaN                  NaN   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                          NaN        NaN                               NaN   \n",
       "1                          NaN        NaN                               NaN   \n",
       "2                          NaN        NaN                               NaN   \n",
       "3                          NaN        NaN                               NaN   \n",
       "4                          NaN        NaN                               NaN   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 NaN         NaN                NaN                NaN   \n",
       "1                 NaN         NaN                NaN                NaN   \n",
       "2                 NaN         NaN                NaN                NaN   \n",
       "3                 NaN         NaN                NaN                NaN   \n",
       "4                 NaN         NaN                NaN                NaN   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5529faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,171):\n",
    "    text = open(f\"articles/{i}.txt\",\"r\",encoding=\"utf-8\").read()\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    #text cleaning:\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    #removing stopwords:\n",
    "    cleaned_text= [word for word in words if word.upper() not in stopwords]\n",
    "    #Word Count:\n",
    "    word_count = len(cleaned_text)\n",
    "    \n",
    "    #Extracting Derived Variables:\n",
    "    positive_words = [word for word in cleaned_text if word.upper() in positive]\n",
    "    negative_words = [word for word in cleaned_text if word.upper() in negative]\n",
    "    positive_score = len(positive_words)\n",
    "    negative_score = len(negative_words)\n",
    "    polarity_score = (positive_score-negative_score)/((positive_score+negative_score)+0.000001)\n",
    "    subjectivity_score = (positive_score+negative_score)/(word_count+0.000001)\n",
    "    \n",
    "    #Analysis of Readability:\n",
    "    sents = sent_tokenize(text)\n",
    "    avg_sentence_length = len(words)/len(sents)\n",
    "    complex_count = 0\n",
    "    for word in words:\n",
    "        if count_syllables(word)>2:\n",
    "            complex_count+=1\n",
    "    perc_complex_words = complex_count/len(words)\n",
    "    fog_index = 0.4 * (avg_sentence_length + perc_complex_words)\n",
    "    \n",
    "    #Personal Pronouns:\n",
    "    personal_pronouns = len(prp.findall(text))\n",
    "    \n",
    "    #Average Word Length:\n",
    "    sum_chars = 0\n",
    "    for word in words:\n",
    "        sum_chars+=len(word)\n",
    "        avg_word_length = sum_chars/len(words)\n",
    "    \n",
    "    #Syllables per word:\n",
    "    tot_syllables = 0\n",
    "    for word in cleaned_text:\n",
    "        tot_syllables += count_syllables(word)\n",
    "    syllables_per_word = tot_syllables/word_count\n",
    "    df.loc[df['URL_ID']==i,'POSITIVE SCORE'] = round(positive_score,2)\n",
    "    df.loc[df['URL_ID']==i,'NEGATIVE SCORE'] = round(negative_score,2)\n",
    "    df.loc[df['URL_ID']==i,'POLARITY SCORE'] = round(polarity_score,2)\n",
    "    df.loc[df['URL_ID']==i,'SUBJECTIVITY SCORE'] = round(subjectivity_score,2)\n",
    "    df.loc[df['URL_ID']==i,'AVG SENTENCE LENGTH'] = round(avg_sentence_length,2)\n",
    "    df.loc[df['URL_ID']==i,'PERCENTAGE OF COMPLEX WORDS'] = round(perc_complex_words,2)\n",
    "    df.loc[df['URL_ID']==i,'FOG INDEX'] = round(fog_index,2)\n",
    "    df.loc[df['URL_ID']==i,'AVG NUMBER OF WORDS PER SENTENCE'] = round(avg_sentence_length,2)\n",
    "    df.loc[df['URL_ID']==i,'COMPLEX WORD COUNT'] = round(complex_count,2)\n",
    "    df.loc[df['URL_ID']==i,'WORD COUNT'] = round(word_count,2)\n",
    "    df.loc[df['URL_ID']==i,'SYLLABLE PER WORD'] = round(syllables_per_word,2)\n",
    "    df.loc[df['URL_ID']==i,'PERSONAL PRONOUNS'] = round(personal_pronouns,2)\n",
    "    df.loc[df['URL_ID']==i,'AVG WORD LENGTH'] = round(avg_word_length,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "069381c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>29.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>11.78</td>\n",
       "      <td>29.29</td>\n",
       "      <td>117.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.04</td>\n",
       "      <td>22.36</td>\n",
       "      <td>0.19</td>\n",
       "      <td>9.02</td>\n",
       "      <td>22.36</td>\n",
       "      <td>122.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>9.35</td>\n",
       "      <td>23.17</td>\n",
       "      <td>374.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>28.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>11.60</td>\n",
       "      <td>28.80</td>\n",
       "      <td>85.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>18.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.35</td>\n",
       "      <td>18.19</td>\n",
       "      <td>228.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>2.09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166.0</td>\n",
       "      <td>https://insights.blackcoffer.com/role-big-data...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>21.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.48</td>\n",
       "      <td>21.01</td>\n",
       "      <td>282.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167.0</td>\n",
       "      <td>https://insights.blackcoffer.com/sales-forecas...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>24.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>9.73</td>\n",
       "      <td>24.08</td>\n",
       "      <td>222.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168.0</td>\n",
       "      <td>https://insights.blackcoffer.com/detect-data-e...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15.72</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.39</td>\n",
       "      <td>15.72</td>\n",
       "      <td>223.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>169.0</td>\n",
       "      <td>https://insights.blackcoffer.com/data-exfiltra...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.59</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.71</td>\n",
       "      <td>21.59</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>170.0</td>\n",
       "      <td>https://insights.blackcoffer.com/impacts-of-co...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>27.81</td>\n",
       "      <td>0.17</td>\n",
       "      <td>11.19</td>\n",
       "      <td>27.81</td>\n",
       "      <td>125.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0       1.0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1       2.0  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2       3.0  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3       4.0  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4       5.0  https://insights.blackcoffer.com/how-artificia...   \n",
       "..      ...                                                ...   \n",
       "165   166.0  https://insights.blackcoffer.com/role-big-data...   \n",
       "166   167.0  https://insights.blackcoffer.com/sales-forecas...   \n",
       "167   168.0  https://insights.blackcoffer.com/detect-data-e...   \n",
       "168   169.0  https://insights.blackcoffer.com/data-exfiltra...   \n",
       "169   170.0  https://insights.blackcoffer.com/impacts-of-co...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               4.0             5.0           -0.11                0.02   \n",
       "1               9.0             6.0            0.20                0.04   \n",
       "2              31.0            23.0            0.15                0.05   \n",
       "3               5.0             1.0            0.67                0.02   \n",
       "4              20.0            17.0            0.08                0.05   \n",
       "..              ...             ...             ...                 ...   \n",
       "165            18.0            40.0           -0.38                0.07   \n",
       "166            21.0            15.0            0.17                0.06   \n",
       "167             4.0            49.0           -0.85                0.09   \n",
       "168             4.0            10.0           -0.43                0.04   \n",
       "169             6.0             9.0           -0.20                0.03   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                  29.29                         0.17      11.78   \n",
       "1                  22.36                         0.19       9.02   \n",
       "2                  23.17                         0.21       9.35   \n",
       "3                  28.80                         0.20      11.60   \n",
       "4                  18.19                         0.19       7.35   \n",
       "..                   ...                          ...        ...   \n",
       "165                21.01                         0.19       8.48   \n",
       "166                24.08                         0.24       9.73   \n",
       "167                15.72                         0.24       6.39   \n",
       "168                21.59                         0.19       8.71   \n",
       "169                27.81                         0.17      11.19   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                               29.29               117.0       432.0   \n",
       "1                               22.36               122.0       392.0   \n",
       "2                               23.17               374.0      1105.0   \n",
       "3                               28.80                85.0       264.0   \n",
       "4                               18.19               228.0       727.0   \n",
       "..                                ...                 ...         ...   \n",
       "165                             21.01               282.0       883.0   \n",
       "166                             24.08               222.0       610.0   \n",
       "167                             15.72               223.0       584.0   \n",
       "168                             21.59               110.0       335.0   \n",
       "169                             27.81               125.0       433.0   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                 2.03                4.0             5.04  \n",
       "1                 2.17                2.0             5.27  \n",
       "2                 2.20               13.0             5.20  \n",
       "3                 2.23                1.0             5.30  \n",
       "4                 2.09               27.0             4.90  \n",
       "..                 ...                ...              ...  \n",
       "165               2.21               15.0             5.05  \n",
       "166               2.31                0.0             5.46  \n",
       "167               2.35                6.0             5.29  \n",
       "168               2.17               11.0             4.86  \n",
       "169               2.14                1.0             5.10  \n",
       "\n",
       "[170 rows x 15 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fff82e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('Output.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a88c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
